{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9pbj8CohK2v8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# loading packages\n",
    "# basic + dates \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "\n",
    "import logging\n",
    "import os \n",
    "\n",
    "import dvc.api\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log (path,file):\n",
    "    '''Creating a log file to record the project's logs'''\n",
    "    #check if file exists\n",
    "    log_file= os.path.join(path,file)\n",
    "\n",
    "    if not os.path.isfile(log_file):\n",
    "        open(log_file,\"w+\").close()\n",
    "\n",
    "    console_logging_format = \"%(levelname)s %(message)s\"\n",
    "    file_logging_format = \"%(levelname)s: %(asctime)s: %(message)s\"\n",
    "\n",
    "    #configure logger\n",
    "    logging.basicConfig(level=logging.INFO,format=console_logging_format)\n",
    "    logger=logging.getLogger()\n",
    "\n",
    "    #file handler for output file\n",
    "    handler=logging.FileHandler(log_file)\n",
    "\n",
    "    #set logging level for file\n",
    "    handler.setLevel(logging.INFO)\n",
    "\n",
    "    #logging format\n",
    "    formatter=logging.Formatter(file_logging_format)\n",
    "    handler.setFormatter(formatter)\n",
    "    \n",
    "    #add handlers to logger\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "id": "twOpmoMNMTjA",
    "outputId": "37fea7b8-2200-4861-a616-1815428197a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014511</th>\n",
       "      <td>1113</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-03-25</td>\n",
       "      <td>5359</td>\n",
       "      <td>590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>9260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Store  DayOfWeek        Date  Sales  Customers  Open  Promo  \\\n",
       "1014511   1113          3  2015-03-25   5359        590     1      0   \n",
       "\n",
       "        StateHoliday  SchoolHoliday StoreType Assortment  CompetitionDistance  \\\n",
       "1014511            0              0         a          c               9260.0   \n",
       "\n",
       "         CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  \\\n",
       "1014511                        0.0                       0.0       0   \n",
       "\n",
       "         Promo2SinceWeek  Promo2SinceYear PromoInterval  \n",
       "1014511              0.0              0.0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set logger file\n",
    "#from logs import log\n",
    "logger=log(path=\"../logs/\",file=\"rossman_sales.logs\")\n",
    "\n",
    "#Loading datasets\n",
    "train=pd.read_csv(\"../data/train.csv\",low_memory=False)\n",
    "test=pd.read_csv(\"../data/test.csv\",low_memory=False)\n",
    "store=pd.read_csv(\"../data/store.csv\",low_memory=False)\n",
    "store['CompetitionDistance'].fillna(store['CompetitionDistance'].median(), inplace = True)\n",
    "train_store=pd.merge(train,store,how='inner',on='Store')\n",
    "train_store.fillna(0,inplace=True)\n",
    "train_store.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zhLOFVhULPIC"
   },
   "outputs": [],
   "source": [
    "train_store['Date']=pd.to_datetime(train_store['Date'])\n",
    "train_store=train_store.sort_values('Date')\n",
    "train_store['Day']=train_store['Date'].dt.day\n",
    "train_store['Month']=train_store['Date'].dt.month\n",
    "train_store['Year']=train_store['Date'].dt.year\n",
    "train_store['WeekOfYear'] = train_store['Date'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-8NjG52LxLC"
   },
   "source": [
    "# Machine Learning\n",
    "\n",
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIAoWS_1LrhT",
    "outputId": "60bb3576-32f8-4a5d-cffc-5b5efbdcc827"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "#drop Date and Open columns\n",
    "#drop rows where Sales=0\n",
    "train_store = train_store.drop(['Date','Open','PromoInterval'],axis=1)\n",
    "train_store = train_store.loc[~(train_store['Sales'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6czrWy5bLrkH"
   },
   "outputs": [],
   "source": [
    "train_store['DayOfWeek']=train_store['DayOfWeek'].apply(str)\n",
    "train_store['Year']=train_store['Year'].apply(str)\n",
    "train_store['Promo']=train_store['Promo'].apply(str)\n",
    "train_store['Promo2']=train_store['Promo2'].apply(str)\n",
    "train_store['SchoolHoliday']=train_store['SchoolHoliday'].apply(str)\n",
    "train_store['StateHoliday']=train_store['StateHoliday'].apply(str)\n",
    "train_store['WeekOfYear']=train_store['WeekOfYear'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuFuKNdyRZ2r",
    "outputId": "99b48c26-1a21-4f33-eda3-245953f87b12"
   },
   "outputs": [],
   "source": [
    "train_store.to_csv('../data/train_store.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/train_store.csv'\n",
    "repo = \"../\"\n",
    "version = \"'v2'\"\n",
    "# return to normal tag version and print in markdown\n",
    "\n",
    "data_url = dvc.api.get_url(\n",
    "    path=path,\n",
    "    repo=repo,\n",
    ")\n",
    "\n",
    "mlflow.set_experiment('Rossmann Pharmeceutical Sales Forecasting')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    df = pd.read_csv('../data/train_store.csv', index_col=0)\n",
    "    mlflow.log_param('data_url', data_url)\n",
    "    mlflow.log_param('data_version', version)\n",
    "    mlflow.log_param('input_rows', df.shape[0])\n",
    "    mlflow.log_param('input_cols', df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pipeline</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 540376\n",
      "Validation set: 135094\n",
      "Test set: 168868\n"
     ]
    }
   ],
   "source": [
    "train,test = train_test_split(train_store,test_size=0.2)\n",
    "train,val = train_test_split(train,test_size=0.2)\n",
    "\n",
    "print('Train set:',len(train))\n",
    "print('Validation set:',len(val))\n",
    "print('Test set:',len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train.drop(['Sales'],axis=1)\n",
    "test_x=test.drop(['Sales'],axis=1)\n",
    "train_y=train[['Sales']]\n",
    "test_y=test[['Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "y0JySuRmLr6Q"
   },
   "outputs": [],
   "source": [
    "cat_cols = ['StateHoliday','SchoolHoliday','DayOfWeek','Promo','Promo2','Assortment','StoreType','Year','WeekOfYear']\n",
    "num_cols = [i for i in train_x.columns if i not in cat_cols]\n",
    "\n",
    "num_transformer = Pipeline(steps = [('imp', IterativeImputer(initial_strategy='median')),\n",
    "                                    ('scaler', StandardScaler())])\n",
    "\n",
    "cat_transformer = Pipeline(steps = [('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('cat',cat_transformer,cat_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression models</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhvIaQ2t6Fud"
   },
   "source": [
    "**Random Forest Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMs-vllbMKK0",
    "outputId": "8075653b-30b9-40f0-8c5b-86bf6e125863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=  10.3s\n",
      "[Pipeline] ..... (step 2 of 2) Processing random_forest, total=11.6min\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 19 features, but ColumnTransformer is expecting 18 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1cda38809dc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrand_forest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#predictions for validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrand_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrand_forest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Downloads\\Anaconda\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    554\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m         if (self._feature_names_in is not None and\n\u001b[0;32m    558\u001b[0m             \u001b[0mX_feature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Anaconda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m             raise ValueError(\n\u001b[1;32m--> 366\u001b[1;33m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 19 features, but ColumnTransformer is expecting 18 features as input."
     ]
    }
   ],
   "source": [
    "rand=Pipeline(steps=[('preprocessor',preprocessor),('random_forest', RandomForestRegressor(max_depth=10,random_state=2))],verbose=True)\n",
    "rand_forest=rand.fit(train_x,train_y.values)\n",
    "#predictions for validation data\n",
    "rand_pred=rand_forest.predict(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGrcDggbFcLK"
   },
   "source": [
    "**Decision Tree Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LF5S9VHkFkmD",
    "outputId": "d52a0077-48f9-42b0-800b-4055f0398717"
   },
   "outputs": [],
   "source": [
    "tree=Pipeline(steps=[('preprocessor',preprocessor),('decision_tree',DecisionTreeRegressor(splitter='random', max_depth=10, random_state=2))],verbose=True)\n",
    "dtree=tree.fit(train_x,train_y.values)\n",
    "#predictions for validation data\n",
    "dtree_pred=dtree.predict(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtybMLQZHAHM"
   },
   "source": [
    "**SGD Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5nl2TKDGkgD",
    "outputId": "6a301020-ab46-440b-e3ac-60c72df554a6"
   },
   "outputs": [],
   "source": [
    "sgdreg=Pipeline(steps=[('preprocessor',preprocessor),('sdg_reg',SGDRegressor(eta0=0.1,fit_intercept=False,shuffle=False,learning_rate='adaptive',random_state=2))],verbose=True)\n",
    "sgd=sgdreg.fit(train_x,train_y.values)\n",
    "#predictions for validation data\n",
    "sgd_pred=sgd.predict(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d42GQ79SHl9K"
   },
   "source": [
    "**Serialising**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[rand_forest,dtree,sgd]\n",
    "with open(\"../pickle/30-07-2021-20-51-03-00.pkl.\", \"wb\") as f:\n",
    "    for model in models:\n",
    "         pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loss function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def loss_function(actual,pred):\n",
    "    rmse=np.sqrt(mean_squared_error(actual,pred))\n",
    "    mae=mean_absolute_error(actual,pred)\n",
    "    r2=r2_score(actual,pred)\n",
    "    return rmse,mae,r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric('RandomForest',loss_function(test_y,rand_pred))\n",
    "mlflow.log_metric('DecisionTree',loss_function(test_y,dtree_pred))\n",
    "mlflow.log_metric('SGDRegression',loss_function(test_y,sgd_pred))\n",
    "\n",
    "mlflow.sklearn.log_model(rand_forest,'random_forest v2')\n",
    "mlflow.sklearn.log_model(dtree,'decision_tree v2')\n",
    "mlflow.sklearn.log_model(sgd,'sgd_regressor v2')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RossmannSalesFeatureEngineering",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
